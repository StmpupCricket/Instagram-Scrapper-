name: Instagram Video Scraper

on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:
  push:
    branches: [ main ]

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - uses: actions/checkout@v4
    
    - uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install playwright==1.40.0
        pip install beautifulsoup4==4.12.2
        python -m playwright install chromium
    
    - name: Create script
      run: |
        mkdir -p scraper
        cat > scraper/scraper.py << 'EOF'
import json
import time
import random
from playwright.sync_api import sync_playwright

def main():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        
        try:
            page.goto("https://www.instagram.com/t20worldcup/")
            time.sleep(5)
            
            videos = []
            for _ in range(5):
                video_elements = page.query_selector_all('video')
                for video in video_elements:
                    src = video.get_attribute('src')
                    if src and src not in videos:
                        videos.append(src)
                
                page.evaluate("window.scrollBy(0, 1000)")
                time.sleep(2)
            
            results = {
                "profile": "@t20worldcup",
                "videos_found": len(videos),
                "video_urls": videos,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            with open('data/videos.json', 'w') as f:
                json.dump(results, f, indent=2)
            
            print(f"Found {len(videos)} videos")
            
        except Exception as e:
            print(f"Error: {e}")
        finally:
            browser.close()

if __name__ == "__main__":
    main()
EOF
    
    - name: Run scraper
      run: |
        mkdir -p data
        cd scraper
        python scraper.py
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: instagram-data
        path: data/
